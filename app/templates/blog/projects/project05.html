{% extends "/blog/base.html" %}
{% block content %}
<div class="grey">
    <div id="project-wide">
        <div><img src="static/images/scraper_wide.png"></div>
    </div>

    <div class="container">
		<div class="row">
            <div class="project-page-info">
                <span class="project-page-title">Reddit Image Scraper</span>

                <a href="/scrape">
                <div class="live-demo-button">
                    <p class="animate">Live Site</p>
                </div>
                </a>

                <div class="github-links">
                    <i class="fa fa-github fa-3x"></i>
                    <a href="https://github.com/kershner/blog/blob/master/app/modules/reddit_scraper.py">Python</a>
                    <a href="https://github.com/kershner/blog/tree/master/app/templates/reddit_scraper">HTML</a>
                    <a href="https://github.com/kershner/blog/blob/master/app/static/scraper_welcome.css">CSS</a>
                </div>

                <div class="technology-used">
                    <span class="tech-title">Technologies Used:</span>
                    <p>Python, HTML, CSS, jQuery, Flask</p>
                </div>
            </div>

            <div class="col-lg-8 col-lg-offset-2">
                <hr>
               <p>
                    A friend of mine was in the habit of grabbing images from Reddit to use as his desktop wallpaper.
                    I thought about how all the manual work involved in finding the links and downloading the images could be automated.
                    The idea for this app came to me and I developed it over a weekend.
                    <br><br>
                    The project was in large part an exercise in refactoring, as I took some old code developed for my GIF Display
                    and re-engineered it to be more Pythonic and better suited to this specific task.  Like the GIF Display,
                    a Python script interfaces with the Reddit API and pulls out image URLs from a specified subreddit.  Those URLs
                    are then put through a number of tests - like making sure the HTTP status code isn't 404 - and then displayed in an
                    organized grid via HTML/CSS.
                    <br><br>
                    Check out the live site!
                    <br>
                </p>
            </div>
        </div>

        <div class="slick-images">
            <div><a href="/static/images/scrape2.jpg"><img src="/static/images/scrape2.jpg"></a></div>
            <div><a href="/static/images/scrape3.jpg"><img src="/static/images/scrape3.jpg"></a></div>
            <div><a href="/static/images/scrape4.jpg"><img src="/static/images/scrape4.jpg"></a></div>
            <div><a href="/static/images/scrape5.jpg"><img src="/static/images/scrape5.jpg"></a></div>
            <div><a href="/static/images/scrape1.jpg"><img src="/static/images/scrape1.jpg"></a></div>
        </div>
    </div>
</div>
<script>
    $(document).ready(function() {
        initSlick();
    });
</script>
{% endblock %}